<!DOCTYPE html
          PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html   xmlns   = "http://www.w3.org/1999/xhtml">
<head>
<link rel="STYLESHEET" href="filtersdk.css" type="text/css" />
<title>ColorSpaces - AviSynth</title>
</head>
<BODY>

<div id="body">

<h1><a href="http://www.avisynth.org/ColorSpaces" style="text-decoration:none">
    ColorSpaces</a>
    	<p>
	</h1>

<h3>RGB Colorspaces</h3>
<p>There are several RGB formats, but the two most widely used are known as RGB24 and RGB32.</p>

<p>Both of them contain three components, R,G and B - short for Red, Green and Blue.</p>

<p>RGB24 and RGB32 are both an <a href="InterleavedImageFormat.htm">InterleavedImageFormat</a>. 
The only difference between the two are that RGB32 contains an extra byte for each pixel.</p>

<p>The extra byte RGB32 contains is known as an alpha pixel, but it is actually quite seldom used. 
The reason RGB32 is considered the "best" format is purely from a programmers view. 
Handling RGB32 material is much easier than RGB24 material, 
because most processors operate on 32bits at the time, and not 24.</p>


<h3>YUY2 Colorspace</h3><p>YUY2 is also an <a href="InterleavedImageFormat.htm">InterleavedImageFormat</a>. 
Bytes are arranged in memory like this:</p>


<p><tt>YUYV|YUYV|YUYV|YUYV|YUYV|YUYV|...</tt></p>

<p><tt>^first byte in a row.</tt></p>


<p>So each pixel horizontally shares UV (chroma) information with a neighboring pixel.</p>



<h3>YV12 Colorspace</h3>
<p>The YV12 colorspace is very different from RGB and YUY2 colorspaces. 
The main different is that it is a <a href="PlanarImageFormat.htm">PlanarImageFormat</a>. 
That means that the different color components are lying separate in memory.</p>


<p>This can in most cases give a significant speedup, since all bytes of each plane can be treated the same way. 
It can also give a speedup because your filter doesn't have to work on all planes, 
if it only modifies one or two of them.</p>



<p>All images are given a pitch. The pitch is basically what can be described as "length of a line". 
What's funny is that the pitch does not have to be equal to the width of the image.</p>

<p>For instance, if you crop something off your image, the only thing that changes 
is the width of your image; the pitch and the actual byte-count of a line remains the same.</p>


<p>The image is then laid out like this:</p>


<p>rrrrrrrrrrrrrrrrpppp</p>

<p>rrrrrrrrrrrrrrrrpppp</p>

<p>rrrrrrrrrrrrrrrrpppp</p>


<p>Where 'r' are the pixels inside the image used, and 'p' is the padding inserted after each line.</p>

<p>In YV12 the Y-plane always has a byte-count that is a multiple of 16, 
but it is still possible to have mod2 width images, because the rowsize is different from the pitch. 
Similar the UV-planes always have a pitch that is a multiple of 8.</p>


<p>When you request frame->GetRowSize(PLANAR_Y) you will get the rowsize of the pixels _inside_ the image. 
When you request frame->GetRowSize(PLANAR_Y_ALIGNED) you will ALWAYS get 
a rowsize that is a multiple of 16 (multiple of 8 on UV planes).</p>


<p>The reason for you to use pitch to get from one line to another is 
that pitch can be even larger than the aligned rowsize - for instance after a crop.</p>


<p>So what you should do is:</p>

<p>- Get a rowsize.</p>

<p>- For each line in the image:</p>

<p>- Process (aligned) rowsize pixels.</p>

<p>- Skip to next line, by adding pitch for the current plane. </p>


<h4>YV12 interlacing</h4><p>YV12 handles interlaced chroma differently than compared to YUY2, 
since YV12 only contains chroma information for every second line. </p>

<p>To enable interlacing, chroma is stretched across two luma lines in the same field!  
That means that luma and chroma aren't directly mappable to lumaline/2 and lumaline/2+1 as with frame based images.</p>


<p>line 0: Chroma for interlaced luma lines 0+2</p>

<p>line 1: Chroma for interlaced luma lines 1+3</p>

<p>line 2: Chroma for interlaced luma lines 4+6</p>

<p>line 3: Chroma for interlaced luma lines 5+7</p>

<p>...etc!</p>


<p>When viewing the individual lines in each plane this maps to:</p>


<p>Consider the separate planes:</p>

<p>Luma:</p>

<p><tt>L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1L1</tt></p>

<p><tt>L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2L2</tt></p>

<p><tt>L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3L3</tt></p>

<p><tt>L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4L4</tt></p>


<p>Chroma that maps to luma plane above:</p>

<p><tt>C1C1C1C1C1C1C1C1C1C1C1</tt></p>

<p><tt>C2C2C2C2C2C2C2C2C2C2C2</tt></p>


<p>Since luma L1 and L3 are in the same field, the chroma information in C1 
is used for these lines and NOT line L1 + L2 as when the image is frame-based. 
C2 is used for lines 2+4 and so on.</p>


<p>This is something that deinterlacers and similar programs need to take into consideration. 
Other filters might rely on the use of Separatefields() and Weave(), to produce framebased images. 
You can use the VideoInfo.IsFieldBased() to check your source, and maybe decide to throw an error, 
or shift to another processing mode.</p>


<p>If your video is fieldbased your vertical resolution (height) must be divisible by 4, 
otherwise AviSynth will not create a new VideoFrame, but will throw an error.</p>


<h3>Links</h3>
<p>See more about <a href="DataStorageInAviSynth.htm">DataStorageInAviSynth</a>.</p>

<p>See a  general introduction to <a href="WorkingWithImages.htm">WorkingWithImages</a>.</p>


</div>
<p><kbd>$Date: 2006/10/28 20:18:12 $</kbd></p>
</BODY>
</html>
