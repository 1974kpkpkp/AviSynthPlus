<!DOCTYPE html
          PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html   xmlns   = "http://www.w3.org/1999/xhtml">
<head>
<link rel="STYLESHEET" href="filtersdk.css" type="text/css" />
<title>DataStorageInAviSynth - AviSynth</title>
</head>
<BODY>
<div id="body">

<h1><a href="http://www.avisynth.org/DataStorageInAviSynth" style="text-decoration:none">
    DataStorageInAviSynth</a>
    	<p>
	</h1>

<h2>Part 1: Actual memory storage</h2><p><em><strong>Warning:</strong> technical.</em> 
Most users will only need to read (and understand) Part 2.</p>


<p>In AviSynth, we process pixels of video data.  These are stored in the memory in the form of data arrays. 
As noted elsewhere (like the <a href="../faq.htm">AviSynth FAQ</a>) 
there are two different colorspaces in v1.0x/2.0x, RGB and YUY2, with a third YV12 added in v2.5. 
These colorspaces store their data in different ways.</p>


<p><strong>RGB</strong> (also known as RGB24): Every pixel is associated with three bytes of data: 
one red, one green, and one blue. They are interleaved (mixed) in the memory like this <tt>RGBRGBRGBRGB</tt>. 
Since data is most easily read in words of four bytes, 
most functions actually process 4 pixels at the same time in order to be able to read 3 words in a row. 
Usually memory is allocated as <tt>aligned</tt> which means that it always allocate memory in words of 4 bytes. 
Since the 3 to 4 relation isn't easy to map, RGB24 is very difficult to work with, and in general isn't recommended. </p>


<p><strong>RGBA</strong> (also known as RGB32): This is an extension of RGB 
where a fourth color channel has been added. This is called the alpha channel, 
and is a definition of transparency in the pixel. 
For an explanation of how the alpha channel is used see <a href="../corefilters/layer.htm">Mask and Layer</a>. 
In general however, you shouldn't rely on filters processing alpha correctly - 
in some cases filters will even produce garbage in this channel.</p>

<p>RGBA also makes this a lot easier as it requires four bytes per pixel, 
and thus each memory access of a word, will correspond to exactly one pixel. 
In fact, RGB will only be used if you have a source that returns RGB or 
if you explicitly use (ConvertToRGB24). 
<a href="../corefilters/convert.htm">ConvertToRGB</a> will by default create RGBA.  
This is the recommended format for RGB-data.</p>


<p><strong>YUY2</strong>: In this colorspace each pair of pixels will share the color data, 
as well as the data being interleaved like this <tt>YUYV|YUYV|YUYV|YUYV</tt>. 
A memory access of one word will get all data for <strong>two</strong> pixels. 
A pair should never be split, as this can create strange artifacts 
when almost all functions in YUY2 assumes that they should read a full word and process that. 
Even if they return the right width when they are done, 
they will most likely have used invalid data when processing valid pixels.</p>


<p><strong>YV12</strong>: Now the real fun begins as this is a <a href="PlanarImageFormat.htm">PlanarImageFormat</a>. 
This means that data is not <a href="InterleavedImageFormat.htm">interleaved</a>, 
but stored separately for each color channel. 
For filter writers this means that they can write one simple function that is called three times, 
one for each color channel, assuming that the operations are channel-independent (not always the case). 
Also, 4 pixels share the color data. These four pixels are a 2x2 matrix, 
i.e. two pairs on adjacent lines in the same field. 
As fields themselves are interleaved, this means that for fieldbased video line 1&amp;3 share color data, 
as well as line 2&amp;4. Framebased video though has the more instinctive way of sharing color, 
line 1&amp;2 share just as line 3&amp;4 does. Again, using <tt>aligned</tt> for both color 
and luma channels will allow easy memory access, and again, 
a 2x2 should never be split as this may create strange artifacts.</p>



<h2>Part 2: How does this affect me as a user?</h2>
<ol><li> As long as you don't split a colorsharing unit it's up to the filterwriters 
to take care of problems with memory reading at end of lines.
</li>
<li> Interlaced (fieldbased) video requires double mod on height.
</li>
<li> Required modulos in different colorspaces.
<ul ><li> <strong>RGB(A)</strong>
<ul ><li> width  mod-1 (no restriction)
</li>
<li> height mod-1 (no restriction) <em>if progressive</em>
</li>
<li> height mod-2 (even values)    <em>if interlaced</em>
</li>
</ul>
</li>
<li> <strong>YUY2</strong>
<ul ><li> width  mod-2 (even values)
</li>
<li> height mod-1 (no restriction) <em>if progressive</em>
</li>
<li> height mod-2 (even values)    <em>if interlaced</em>
</li>
</ul>
</li>
<li> <strong>YV12</strong>
<ul ><li> width  mod-2 (even values)
</li>
<li> height mod-2 (even values)    <em>if progressive</em>
</li>
<li> height mod-4                  <em>if interlaced</em>
</li>
</ul>
</li>
</ul>
</li>
<li>Examples of valid <a href="../corefilters/crop.htm">Crops</a> with input 320x240 progressive
<ul ><li> <strong>RGB(A)</strong>
<ul ><li>Crop(1,7,-32,-19)
</li>
<li>Crop(2,4,300,196)
</li>
</ul>
</li>
<li> <strong>YUY2</strong>
<ul ><li>Crop(2,7,-32,-19)
</li>
<li>Crop(2,4,300,196)
</li>
</ul>
</li>
<li> <strong>YV12</strong>
<ul ><li>Crop(2,8,-32,-18)
</li>
<li>Crop(2,4,300,196)
</li>
</ul>
</li>
</ul>
</li>
<li> Note that final video may have other restrictions, most MPEG-n implementations 
want mod-16 on all resolutions etc.
</li>
</ol>

<h2>More information</h2>
<p>See more about <a href="ColorSpaces.htm">ColorSpaces</a>.</p>

<p>See a  general introduction to <a href="WorkingWithImages.htm">WorkingWithImages</a>.</p>


<hr />
<p><tt>This page is a edited summary of <a href="http://forum.doom9.org/showthread.php?s=&threadid=40413&highlight=YV12">[this thread at Doom9's forum]</a></tt></p>

</div>
<p><kbd>$Date: 2006/10/28 20:18:13 $</kbd></p>
</BODY>
</html>
